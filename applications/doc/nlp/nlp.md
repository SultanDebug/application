### 名词定义
> - 分类：标注或规则进行文本分类，只属于一种，非此即彼
> - 聚类：无标注，统计判断文本是否相似，归为一类
---
> - 模型：f(x) = w*x+b
> - 特征:事务特征转化为数值
> - 语料：数据样本
> - 监督学习：数据样本已标注结果
> - 无监督学习：数据样本未标注结果
---
> - 齐夫定律：一个词的词频和它的词频排名成反比
---
### 规则分词
> - 双数组字典树：base，check，base记录状态转移偏移量，check记录当前节点前置节点用来验证转移是否正确
> - 定义：当b接受c转移到状态p时，满足如下公式
>> p = base[b]+c 且 base[b] = check[p]
> - 如上也可知，双数组时间复杂度为常数,加一些处理，如终止节点标记、value数组等，可作为map使用，更省内存更快

> - ac自动机
> - goto表：状态转移 output表：当前状态可输出的模式串 fail表：转移失败回溯最佳状态表【已匹配模式串的最长后缀状态】
> - goto表用dat替换，即可得到最优数据结构，对长模式匹配具有最优性能

#### 效果指标
> 混淆矩阵
> > TP：真阳 FP：假阳 TN：真阴 FN：假阴
> - P值：准确率-预测结果中正类结果比例， TP/(TP+FP)
> - R值：召回率-所有正类结果中被预测正确的比例，TP/(TP+FN)
> - F1值：2*P*R/(P+R)
> - OOV:未登录词-未在预料收录的词
> - IV：登录词-已收录的词

### 统计分词
- 概率语言模型：给定一个句子，计算句子出现的概率
- 数据稀疏：概率大多相同，导致区分度不够
> - 整个句子作为语言概率，数据太稀疏，几乎没有相同的句子
> > - 计算每个词的后验概率，即：P(W(t)|w(0)W(1)...W(t-1)),每个词的后验概率相乘作为句子的概率模型
> > - 使用极大似然估计，P(W(t)|w(0)W(1)...W(t-1)) = C(w(0)...C(t))/C(w(0)...C(t-1))
> - 上述模型对长文本还是稀疏且计算量大，对OOV句子非常不友好
> > - 马尔可夫链（n元语法）：概率计算修改为后验概率只计算前置n-1个事件概率，常用的时二元语法
> > - 定义：P(W(t)) = P(W(1)|W(0))+...P(W(t)|W(t-1))
> > - 平滑策略：n越大，数据越稀疏，会有很多句子概率突然降为0，需要平衡
> - 维特比算法：从前往后算最短路径，再从后往前回溯后缀最短，更新完成即得全局最短路径